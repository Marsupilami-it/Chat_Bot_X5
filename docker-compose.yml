services:
  frontend:
    build: ./frontend
    container_name: frontend
    ports:
      - 8501:8501
    volumes:
      - ./frontend:/app
    restart: always

  api-service:
    build: ./api-service
    container_name: api-service
    healthcheck:
      test: curl -f http://localhost:5000/version || exit 1
      interval: 5s
      timeout: 2s
      retries: 3

  ml-service:
    build: ./ml-service
    container_name: ml-service
    volumes:
      - chroma_data:/app/db
    environment:
      - CHROMA_DB_PATH=/app/db
    platform: linux/amd64
    restart: unless-stopped


#  ollama-service:
#    image: ollama/ollama:latest
#    container_name: ollama-service
#    ports:
#      - "11434:11434"
#    environment:
#      - OLLAMA_MODEL=llama2
#    entrypoint: [ "ollama", "run", "gemma2:9b" ]
#    restart: unless-stopped
#    platform: linux/amd64

volumes:
  #  main-db:
  #    external: true
  chroma_data:
    driver: local
